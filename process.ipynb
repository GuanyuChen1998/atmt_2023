{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"SDncC3twZ7Ti","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699293111727,"user_tz":-60,"elapsed":6998,"user":{"displayName":"陈冠宇","userId":"06424016712515072891"}},"outputId":"f00c9d4e-82f2-4e7a-c71b-93c1434dcef5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sacrebleu\n","  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/118.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m112.6/118.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting portalocker (from sacrebleu)\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.6.3)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.23.5)\n","Collecting colorama (from sacrebleu)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.3)\n","Installing collected packages: portalocker, colorama, sacrebleu\n","Successfully installed colorama-0.4.6 portalocker-2.8.2 sacrebleu-2.3.1\n"]}],"source":["from google.colab import drive\n","import os\n","\n","!pip install sacrebleu"]},{"cell_type":"code","source":["drive.mount('/content/drive')\n","\n","new_directory = '/content/drive/My Drive/23HS/MT'\n","\n","os.chdir(new_directory)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y748x9xncYNr","outputId":"621dc798-af5a-4a45-8780-23f449f6fa17","executionInfo":{"status":"ok","timestamp":1699293129867,"user_tz":-60,"elapsed":16163,"user":{"displayName":"陈冠宇","userId":"06424016712515072891"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#!git clone https://github.com/GuanyuChen1998/atmt_2023.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FnhtVecEao5U","outputId":"e3dbcb0c-468a-4270-a464-64ee7140a7a0","executionInfo":{"status":"ok","timestamp":1699293142715,"user_tz":-60,"elapsed":683,"user":{"displayName":"陈冠宇","userId":"06424016712515072891"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'atmt_2023' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["new_directory = '/content/drive/My Drive/23HS/MT/atmt_2023'\n","\n","os.chdir(new_directory)"],"metadata":{"id":"NoBOQHWVeuQ2","executionInfo":{"status":"ok","timestamp":1699293153090,"user_tz":-60,"elapsed":230,"user":{"displayName":"陈冠宇","userId":"06424016712515072891"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SbpdkC4qw82G","executionInfo":{"status":"ok","timestamp":1699293159993,"user_tz":-60,"elapsed":320,"user":{"displayName":"陈冠宇","userId":"06424016712515072891"}},"outputId":"325db7bf-a6fa-493b-880f-6944b818d068"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["assignments  moses_scripts  __pycache__       scripts  train.py\n","data\t     preprocess.py  README.md\t      seq2seq  translate_beam.py\n","LICENSE      process.ipynb  requirements.txt  share    translate.py\n"]}]},{"cell_type":"code","source":["!python train.py \\\n","--data data/en-fr/prepared \\\n","--source-lang fr \\\n","--target-lang en \\\n","--save-dir assignments/03/baseline/checkpoints \\\n","--batch-size 8\\\n","--restore-file None \\\n","--cuda"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qXRDNsn2e0lP","outputId":"05d29ea2-afa4-4809-b9c2-a2d6f75f01ae","executionInfo":{"status":"ok","timestamp":1699296255785,"user_tz":-60,"elapsed":2109357,"user":{"displayName":"陈冠宇","userId":"06424016712515072891"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO: Commencing training!\n","INFO: COMMAND: train.py --data data/en-fr/prepared --source-lang fr --target-lang en --save-dir assignments/03/baseline/checkpoints --batch-size 8 --restore-file None --cuda\n","INFO: Arguments: {'cuda': True, 'data': 'data/en-fr/prepared', 'source_lang': 'fr', 'target_lang': 'en', 'max_tokens': None, 'batch_size': 8, 'train_on_tiny': False, 'arch': 'lstm', 'max_epoch': 10000, 'clip_norm': 4.0, 'lr': 0.0003, 'patience': 3, 'log_file': None, 'save_dir': 'assignments/03/baseline/checkpoints', 'restore_file': 'None', 'save_interval': 1, 'no_save': False, 'epoch_checkpoints': False, 'encoder_embed_dim': 64, 'encoder_embed_path': None, 'encoder_hidden_size': 64, 'encoder_num_layers': 1, 'encoder_bidirectional': 'True', 'encoder_dropout_in': 0.25, 'encoder_dropout_out': 0.25, 'decoder_embed_dim': 64, 'decoder_embed_path': None, 'decoder_hidden_size': 128, 'decoder_num_layers': 1, 'decoder_dropout_in': 0.25, 'decoder_dropout_out': 0.25, 'decoder_use_attention': 'True', 'decoder_use_lexical_model': 'False', 'device_id': 0}\n","INFO: Loaded a source dictionary (fr) with 4000 words\n","INFO: Loaded a target dictionary (en) with 4000 words\n","INFO: Built a model with 1308576 parameters\n","INFO: Epoch 000: loss 5.006 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 12.16 | clip 0.9768\n","INFO: Epoch 000: valid_loss 5.16 | num_tokens 9.14 | batch_size 500 | valid_perplexity 174\n","INFO: Epoch 001: loss 4.407 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 11.08 | clip 1\n","INFO: Epoch 001: valid_loss 4.85 | num_tokens 9.14 | batch_size 500 | valid_perplexity 127\n","INFO: Epoch 002: loss 4.158 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 11.32 | clip 1\n","INFO: Epoch 002: valid_loss 4.52 | num_tokens 9.14 | batch_size 500 | valid_perplexity 91.9\n","INFO: Epoch 003: loss 3.965 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 11.76 | clip 1\n","INFO: Epoch 003: valid_loss 4.35 | num_tokens 9.14 | batch_size 500 | valid_perplexity 77.5\n","INFO: Epoch 004: loss 3.8 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 12.4 | clip 1\n","INFO: Epoch 004: valid_loss 4.23 | num_tokens 9.14 | batch_size 500 | valid_perplexity 68.6\n","INFO: Epoch 005: loss 3.66 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 13.03 | clip 1\n","INFO: Epoch 005: valid_loss 4.08 | num_tokens 9.14 | batch_size 500 | valid_perplexity 59.2\n","INFO: Epoch 006: loss 3.526 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 13.44 | clip 1\n","INFO: Epoch 006: valid_loss 3.97 | num_tokens 9.14 | batch_size 500 | valid_perplexity 53.1\n","INFO: Epoch 007: loss 3.409 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 13.93 | clip 1\n","INFO: Epoch 007: valid_loss 3.91 | num_tokens 9.14 | batch_size 500 | valid_perplexity 50.1\n","INFO: Epoch 008: loss 3.307 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 14.42 | clip 1\n","INFO: Epoch 008: valid_loss 3.76 | num_tokens 9.14 | batch_size 500 | valid_perplexity 43.1\n","INFO: Epoch 009: loss 3.211 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 14.93 | clip 1\n","INFO: Epoch 009: valid_loss 3.68 | num_tokens 9.14 | batch_size 500 | valid_perplexity 39.6\n","INFO: Epoch 010: loss 3.127 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 15.38 | clip 1\n","INFO: Epoch 010: valid_loss 3.64 | num_tokens 9.14 | batch_size 500 | valid_perplexity 38\n","INFO: Epoch 011: loss 3.053 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 15.9 | clip 1\n","INFO: Epoch 011: valid_loss 3.5 | num_tokens 9.14 | batch_size 500 | valid_perplexity 33.1\n","INFO: Epoch 012: loss 2.979 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 16.28 | clip 1\n","INFO: Epoch 012: valid_loss 3.48 | num_tokens 9.14 | batch_size 500 | valid_perplexity 32.5\n","INFO: Epoch 013: loss 2.918 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 16.62 | clip 1\n","INFO: Epoch 013: valid_loss 3.35 | num_tokens 9.14 | batch_size 500 | valid_perplexity 28.4\n","INFO: Epoch 014: loss 2.844 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 16.85 | clip 1\n","INFO: Epoch 014: valid_loss 3.32 | num_tokens 9.14 | batch_size 500 | valid_perplexity 27.7\n","INFO: Epoch 015: loss 2.79 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 17.13 | clip 1\n","INFO: Epoch 015: valid_loss 3.24 | num_tokens 9.14 | batch_size 500 | valid_perplexity 25.7\n","INFO: Epoch 016: loss 2.725 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 17.51 | clip 1\n","INFO: Epoch 016: valid_loss 3.24 | num_tokens 9.14 | batch_size 500 | valid_perplexity 25.5\n","INFO: Epoch 017: loss 2.674 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 17.82 | clip 1\n","INFO: Epoch 017: valid_loss 3.17 | num_tokens 9.14 | batch_size 500 | valid_perplexity 23.8\n","INFO: Epoch 018: loss 2.619 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 18.22 | clip 1\n","INFO: Epoch 018: valid_loss 3.13 | num_tokens 9.14 | batch_size 500 | valid_perplexity 22.8\n","INFO: Epoch 019: loss 2.576 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 18.57 | clip 1\n","INFO: Epoch 019: valid_loss 3.09 | num_tokens 9.14 | batch_size 500 | valid_perplexity 22\n","INFO: Epoch 020: loss 2.524 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 18.77 | clip 1\n","INFO: Epoch 020: valid_loss 3.04 | num_tokens 9.14 | batch_size 500 | valid_perplexity 20.9\n","INFO: Epoch 021: loss 2.476 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 19.19 | clip 1\n","INFO: Epoch 021: valid_loss 3.03 | num_tokens 9.14 | batch_size 500 | valid_perplexity 20.8\n","INFO: Epoch 022: loss 2.431 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 19.48 | clip 1\n","INFO: Epoch 022: valid_loss 2.94 | num_tokens 9.14 | batch_size 500 | valid_perplexity 18.8\n","INFO: Epoch 023: loss 2.387 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 19.62 | clip 1\n","INFO: Epoch 023: valid_loss 2.92 | num_tokens 9.14 | batch_size 500 | valid_perplexity 18.5\n","INFO: Epoch 024: loss 2.346 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 19.84 | clip 1\n","INFO: Epoch 024: valid_loss 2.88 | num_tokens 9.14 | batch_size 500 | valid_perplexity 17.8\n","INFO: Epoch 025: loss 2.304 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 20.05 | clip 1\n","INFO: Epoch 025: valid_loss 2.87 | num_tokens 9.14 | batch_size 500 | valid_perplexity 17.6\n","INFO: Epoch 026: loss 2.265 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 20.42 | clip 1\n","INFO: Epoch 026: valid_loss 2.81 | num_tokens 9.14 | batch_size 500 | valid_perplexity 16.5\n","INFO: Epoch 027: loss 2.228 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 20.63 | clip 1\n","INFO: Epoch 027: valid_loss 2.8 | num_tokens 9.14 | batch_size 500 | valid_perplexity 16.4\n","INFO: Epoch 028: loss 2.197 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 20.75 | clip 1\n","INFO: Epoch 028: valid_loss 2.76 | num_tokens 9.14 | batch_size 500 | valid_perplexity 15.9\n","INFO: Epoch 029: loss 2.16 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 20.91 | clip 1\n","INFO: Epoch 029: valid_loss 2.71 | num_tokens 9.14 | batch_size 500 | valid_perplexity 15.1\n","INFO: Epoch 030: loss 2.125 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 21.11 | clip 1\n","INFO: Epoch 030: valid_loss 2.7 | num_tokens 9.14 | batch_size 500 | valid_perplexity 14.9\n","INFO: Epoch 031: loss 2.089 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 21.04 | clip 1\n","INFO: Epoch 031: valid_loss 2.69 | num_tokens 9.14 | batch_size 500 | valid_perplexity 14.7\n","INFO: Epoch 032: loss 2.065 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 21.35 | clip 1\n","INFO: Epoch 032: valid_loss 2.66 | num_tokens 9.14 | batch_size 500 | valid_perplexity 14.4\n","INFO: Epoch 033: loss 2.036 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 21.88 | clip 1\n","INFO: Epoch 033: valid_loss 2.64 | num_tokens 9.14 | batch_size 500 | valid_perplexity 14\n","INFO: Epoch 034: loss 2.009 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 21.8 | clip 1\n","INFO: Epoch 034: valid_loss 2.61 | num_tokens 9.14 | batch_size 500 | valid_perplexity 13.5\n","INFO: Epoch 035: loss 1.978 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 21.8 | clip 1\n","INFO: Epoch 035: valid_loss 2.58 | num_tokens 9.14 | batch_size 500 | valid_perplexity 13.2\n","INFO: Epoch 036: loss 1.951 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 21.94 | clip 1\n","INFO: Epoch 036: valid_loss 2.57 | num_tokens 9.14 | batch_size 500 | valid_perplexity 13.1\n","INFO: Epoch 037: loss 1.925 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 21.92 | clip 1\n","INFO: Epoch 037: valid_loss 2.59 | num_tokens 9.14 | batch_size 500 | valid_perplexity 13.3\n","INFO: Epoch 038: loss 1.898 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 22.16 | clip 1\n","INFO: Epoch 038: valid_loss 2.53 | num_tokens 9.14 | batch_size 500 | valid_perplexity 12.6\n","INFO: Epoch 039: loss 1.873 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 22.37 | clip 1\n","INFO: Epoch 039: valid_loss 2.54 | num_tokens 9.14 | batch_size 500 | valid_perplexity 12.7\n","INFO: Epoch 040: loss 1.845 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 22.69 | clip 1\n","INFO: Epoch 040: valid_loss 2.52 | num_tokens 9.14 | batch_size 500 | valid_perplexity 12.4\n","INFO: Epoch 041: loss 1.819 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 22.67 | clip 1\n","INFO: Epoch 041: valid_loss 2.5 | num_tokens 9.14 | batch_size 500 | valid_perplexity 12.2\n","INFO: Epoch 042: loss 1.8 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 22.59 | clip 1\n","INFO: Epoch 042: valid_loss 2.48 | num_tokens 9.14 | batch_size 500 | valid_perplexity 11.9\n","INFO: Epoch 043: loss 1.776 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 22.59 | clip 1\n","INFO: Epoch 043: valid_loss 2.49 | num_tokens 9.14 | batch_size 500 | valid_perplexity 12\n","INFO: Epoch 044: loss 1.757 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 22.75 | clip 1\n","INFO: Epoch 044: valid_loss 2.47 | num_tokens 9.14 | batch_size 500 | valid_perplexity 11.8\n","INFO: Epoch 045: loss 1.741 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 22.87 | clip 1\n","INFO: Epoch 045: valid_loss 2.48 | num_tokens 9.14 | batch_size 500 | valid_perplexity 11.9\n","INFO: Epoch 046: loss 1.722 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 23.19 | clip 1\n","INFO: Epoch 046: valid_loss 2.47 | num_tokens 9.14 | batch_size 500 | valid_perplexity 11.8\n","INFO: Epoch 047: loss 1.696 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 23.01 | clip 1\n","INFO: Epoch 047: valid_loss 2.45 | num_tokens 9.14 | batch_size 500 | valid_perplexity 11.6\n","INFO: Epoch 048: loss 1.683 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 23.04 | clip 1\n","INFO: Epoch 048: valid_loss 2.44 | num_tokens 9.14 | batch_size 500 | valid_perplexity 11.5\n","INFO: Epoch 049: loss 1.664 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 23.1 | clip 1\n","INFO: Epoch 049: valid_loss 2.43 | num_tokens 9.14 | batch_size 500 | valid_perplexity 11.4\n","INFO: Epoch 050: loss 1.644 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 23.32 | clip 1\n","INFO: Epoch 050: valid_loss 2.44 | num_tokens 9.14 | batch_size 500 | valid_perplexity 11.5\n","INFO: Epoch 051: loss 1.63 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 23.45 | clip 1\n","INFO: Epoch 051: valid_loss 2.4 | num_tokens 9.14 | batch_size 500 | valid_perplexity 11\n","INFO: Epoch 052: loss 1.616 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 23.44 | clip 1\n","INFO: Epoch 052: valid_loss 2.4 | num_tokens 9.14 | batch_size 500 | valid_perplexity 11\n","INFO: Epoch 053: loss 1.594 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 23.39 | clip 1\n","INFO: Epoch 053: valid_loss 2.4 | num_tokens 9.14 | batch_size 500 | valid_perplexity 11.1\n","INFO: Epoch 054: loss 1.583 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 23.6 | clip 1\n","INFO: Epoch 054: valid_loss 2.4 | num_tokens 9.14 | batch_size 500 | valid_perplexity 11\n","INFO: Epoch 055: loss 1.562 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 23.63 | clip 1\n","INFO: Epoch 055: valid_loss 2.42 | num_tokens 9.14 | batch_size 500 | valid_perplexity 11.2\n","INFO: Epoch 056: loss 1.549 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 23.69 | clip 1\n","INFO: Epoch 056: valid_loss 2.4 | num_tokens 9.14 | batch_size 500 | valid_perplexity 11.1\n","INFO: Epoch 057: loss 1.533 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 23.8 | clip 1\n","INFO: Epoch 057: valid_loss 2.38 | num_tokens 9.14 | batch_size 500 | valid_perplexity 10.8\n","INFO: Epoch 058: loss 1.515 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 23.73 | clip 1\n","INFO: Epoch 058: valid_loss 2.39 | num_tokens 9.14 | batch_size 500 | valid_perplexity 10.9\n","INFO: Epoch 059: loss 1.5 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 23.86 | clip 1\n","INFO: Epoch 059: valid_loss 2.36 | num_tokens 9.14 | batch_size 500 | valid_perplexity 10.6\n","INFO: Epoch 060: loss 1.492 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 24.03 | clip 1\n","INFO: Epoch 060: valid_loss 2.36 | num_tokens 9.14 | batch_size 500 | valid_perplexity 10.6\n","INFO: Epoch 061: loss 1.474 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 23.69 | clip 1\n","INFO: Epoch 061: valid_loss 2.36 | num_tokens 9.14 | batch_size 500 | valid_perplexity 10.6\n","INFO: Epoch 062: loss 1.467 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 23.87 | clip 1\n","INFO: Epoch 062: valid_loss 2.34 | num_tokens 9.14 | batch_size 500 | valid_perplexity 10.4\n","INFO: Epoch 063: loss 1.449 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 23.97 | clip 1\n","INFO: Epoch 063: valid_loss 2.34 | num_tokens 9.14 | batch_size 500 | valid_perplexity 10.4\n","INFO: Epoch 064: loss 1.437 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 24.1 | clip 1\n","INFO: Epoch 064: valid_loss 2.33 | num_tokens 9.14 | batch_size 500 | valid_perplexity 10.3\n","INFO: Epoch 065: loss 1.427 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 23.97 | clip 1\n","INFO: Epoch 065: valid_loss 2.34 | num_tokens 9.14 | batch_size 500 | valid_perplexity 10.4\n","INFO: Epoch 066: loss 1.413 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 24 | clip 1\n","INFO: Epoch 066: valid_loss 2.33 | num_tokens 9.14 | batch_size 500 | valid_perplexity 10.3\n","INFO: Epoch 067: loss 1.401 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 24.1 | clip 1\n","INFO: Epoch 067: valid_loss 2.32 | num_tokens 9.14 | batch_size 500 | valid_perplexity 10.2\n","INFO: Epoch 068: loss 1.389 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 24.2 | clip 1\n","INFO: Epoch 068: valid_loss 2.34 | num_tokens 9.14 | batch_size 500 | valid_perplexity 10.3\n","INFO: Epoch 069: loss 1.385 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 24.42 | clip 1\n","INFO: Epoch 069: valid_loss 2.33 | num_tokens 9.14 | batch_size 500 | valid_perplexity 10.3\n","INFO: Epoch 070: loss 1.368 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 24.08 | clip 1\n","INFO: Epoch 070: valid_loss 2.31 | num_tokens 9.14 | batch_size 500 | valid_perplexity 10.1\n","INFO: Epoch 071: loss 1.356 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 24.29 | clip 1\n","INFO: Epoch 071: valid_loss 2.32 | num_tokens 9.14 | batch_size 500 | valid_perplexity 10.1\n","INFO: Epoch 072: loss 1.349 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 24.39 | clip 1\n","INFO: Epoch 072: valid_loss 2.31 | num_tokens 9.14 | batch_size 500 | valid_perplexity 10.1\n","INFO: Epoch 073: loss 1.336 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 24.26 | clip 1\n","INFO: Epoch 073: valid_loss 2.29 | num_tokens 9.14 | batch_size 500 | valid_perplexity 9.92\n","INFO: Epoch 074: loss 1.323 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 24.03 | clip 1\n","INFO: Epoch 074: valid_loss 2.3 | num_tokens 9.14 | batch_size 500 | valid_perplexity 9.93\n","INFO: Epoch 075: loss 1.319 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 24.17 | clip 1\n","INFO: Epoch 075: valid_loss 2.3 | num_tokens 9.14 | batch_size 500 | valid_perplexity 9.96\n","INFO: Epoch 076: loss 1.308 | lr 0.0003 | num_tokens 9.1 | batch_size 8 | grad_norm 24.14 | clip 1\n","INFO: Epoch 076: valid_loss 2.31 | num_tokens 9.14 | batch_size 500 | valid_perplexity 10.1\n","INFO: No validation set improvements observed for 3 epochs. Early stop!\n"]}]},{"cell_type":"code","source":["!python translate.py \\\n","--data data/en-fr/prepared \\\n","--dicts data/en-fr/prepared \\\n","--checkpoint-path assignments/03/baseline/checkpoints/checkpoint_last.pt \\\n","--output assignments/03/baseline/test_translations.txt \\\n","--cuda \\\n","--batch-size 1024"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"02yDvKo4fv79","outputId":"6eacc212-d8d7-4c3d-ac78-95fb19688a6b","executionInfo":{"status":"ok","timestamp":1699296276489,"user_tz":-60,"elapsed":10461,"user":{"displayName":"陈冠宇","userId":"06424016712515072891"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[2023-11-06 18:44:25] COMMAND: translate.py --data data/en-fr/prepared --dicts data/en-fr/prepared --checkpoint-path assignments/03/baseline/checkpoints/checkpoint_last.pt --output assignments/03/baseline/test_translations.txt --cuda --batch-size 1024\n","[2023-11-06 18:44:25] Arguments: {'cuda': True, 'data': 'data/en-fr/prepared', 'source_lang': 'fr', 'target_lang': 'en', 'max_tokens': None, 'batch_size': 1024, 'train_on_tiny': False, 'arch': 'lstm', 'max_epoch': 10000, 'clip_norm': 4.0, 'lr': 0.0003, 'patience': 3, 'log_file': None, 'save_dir': 'assignments/03/baseline/checkpoints', 'restore_file': 'None', 'save_interval': 1, 'no_save': False, 'epoch_checkpoints': False, 'encoder_embed_dim': 64, 'encoder_embed_path': None, 'encoder_hidden_size': 64, 'encoder_num_layers': 1, 'encoder_bidirectional': 'True', 'encoder_dropout_in': 0.25, 'encoder_dropout_out': 0.25, 'decoder_embed_dim': 64, 'decoder_embed_path': None, 'decoder_hidden_size': 128, 'decoder_num_layers': 1, 'decoder_dropout_in': 0.25, 'decoder_dropout_out': 0.25, 'decoder_use_attention': 'True', 'decoder_use_lexical_model': 'False', 'device_id': 0, 'seed': 42, 'dicts': 'data/en-fr/prepared', 'checkpoint_path': 'assignments/03/baseline/checkpoints/checkpoint_last.pt', 'output': 'assignments/03/baseline/test_translations.txt', 'max_len': 128}\n","[2023-11-06 18:44:25] Loaded a source dictionary (fr) with 4000 words\n","[2023-11-06 18:44:25] Loaded a target dictionary (en) with 4000 words\n","[2023-11-06 18:44:26] Loaded a model from checkpoint assignments/03/baseline/checkpoints/checkpoint_last.pt\n"]}]},{"cell_type":"code","source":["!bash scripts/postprocess.sh \\\n","assignments/03/baseline/test_translations.txt \\\n","assignments/03/baseline/test_translations.p.txt en"],"metadata":{"id":"NwTbPnibi0q4","executionInfo":{"status":"ok","timestamp":1699296281523,"user_tz":-60,"elapsed":238,"user":{"displayName":"陈冠宇","userId":"06424016712515072891"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["!cat assignments/03/baseline/test_translations.p.txt | sacrebleu data/en-fr/raw/test.en"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HSnbNKIqi8ln","outputId":"f35f4313-c72c-41ef-ac45-8de30c917914","executionInfo":{"status":"ok","timestamp":1699296284397,"user_tz":-60,"elapsed":347,"user":{"displayName":"陈冠宇","userId":"06424016712515072891"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n"," \"name\": \"BLEU\",\n"," \"score\": 18.4,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.3.1\",\n"," \"verbose_score\": \"49.2/24.2/13.1/7.3 (BP = 1.000 ratio = 1.168 hyp_len = 4544 ref_len = 3892)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.3.1\"\n","}\n","\u001b[0m"]}]}]}